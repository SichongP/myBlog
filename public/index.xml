<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic on Academic</title>
    <link>/</link>
    <description>Recent content in Academic on Academic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Write scientific paper in markdown</title>
      <link>/post/2019-08-07-write-scientific-paper-in-markdown/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-08-07-write-scientific-paper-in-markdown/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;If you have ever written a scientific paper in MS Word (or any other word processing software) then you&amp;rsquo;re probably experienced frustrations like me: Word constantly crashing when loaded with too many high-resolution figures, citations getting messed up when working with others that use different citation managers, or hard to keep track of hundreds of versions of the draft, etc.&lt;/p&gt;

&lt;p&gt;Of course, Latex is always an excellent solution to all those problems. It separates content and formatting, allowing you to focus on content and leave the rest to those with expertise at it. A Tex file is also a pure text format so it&amp;rsquo;s easy to manage with a version control tool like git. However, Latex does have a rather steep learning curve. And a Tex file is not the most intuitive format to look at. For example, look at the below Tex format: &lt;img src=&#34;/img/Tex_example.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another problem with writing in Latex is, while it&amp;rsquo;s not easy to learn Latex, it&amp;rsquo;s even harder to get all your collaborators on board, which is usually the case with scientific papers.&lt;/p&gt;

&lt;p&gt;That led me to think: markdown is a fantastic format that is both intuitive and powerful. Why not write in markdown? After a short search, I&amp;rsquo;m happy to report that this is indeed possible!&lt;/p&gt;

&lt;h1 id=&#34;what-does-writing-a-scientific-paper-require&#34;&gt;What does writing a scientific paper require?&lt;/h1&gt;

&lt;p&gt;Content aside, to write a scientific paper efficiently, one needs at least the following elements:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Easy way to insert and manage&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Hypothesis testing and multiple test correction</title>
      <link>/post/fdr-correction/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/fdr-correction/</guid>
      <description>


&lt;div id=&#34;why-multiple-testing-correction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why multiple testing correction?&lt;/h2&gt;
&lt;p&gt;Multiple testing refers to a practice where we apply the same statistical test &lt;em&gt;independantly&lt;/em&gt; multiple times. This raises a problem that’s related to hypothesis testing: the more independant tests we do, the more inflated our false positive rate becomes. Here I’m gonna use a simple example to explain why multiple testing correction is crucial for hypothesis testing.&lt;/p&gt;
&lt;div id=&#34;an-example---are-you-being-cheated&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;An example - Are you being cheated?&lt;/h3&gt;
&lt;p&gt;Imagine that you’re playing a game where the host lets you flip a coin, if it’s a head, you get a point. If it’s a tail, the host gets a point. Whoever gets 20 points first wins the game. Does this sound like a fair game to you?&lt;/p&gt;
&lt;p&gt;In this scenario, when we say the game is “fair”, we are implying that the coin is an average, normal coin, which gives you 50/50 chance for a head or a tail. But is this true?&lt;/p&gt;
&lt;p&gt;Intuitively, we may find a coin that flips tail 10 times in a row quite suspicious. But what about 6 times in a row? 3 times? 9 out of 10 times? 3 out of 4 times? At which point do we decide to call it a fraud? Here is where hypothesis testing comes into play.&lt;/p&gt;
&lt;p&gt;When we look at this scenario, we first assume that coin is normal, which gives us an expectation: the percentages of heads and tails are roughly 50% each. Then we flip the coin multiple times, observe the frequency of heads and tails and make a decision based on our observed data: does it comply with our expectation or does it deviate so much that we feel safe to say that our assumption of fairness was wrong?&lt;/p&gt;
&lt;p&gt;The process above is essentially a hypothesis testing:
1. For a question, we formulate a null hypothesis and its alternative hypothesis
2. Based on our hypothesis, we draw some expectations of data assuming null hypothesis true
3. Carry out experiment, collect data and compare observed data to our expected data.
4. Make a decision - are we able to reject our null hypothesis or not?&lt;/p&gt;
&lt;p&gt;In the coin flip example, if we record 1 everytime we get a head and -1 everytime we get a tail, after many times of flips, we would expect to get a mean score of 0. Let’s simulate this process in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flips = sample(c(-1,1), 20, replace = TRUE, prob = c(0.5, 0.5))
flips&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  1  1 -1  1 -1  1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code, by setting &lt;code&gt;prob=c(0.5, 0.5)&lt;/code&gt;, we’re saying this is a fair coin. Now let’s see what the mean we got from this simulation is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(flips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s not 0 as we expected it to be, even though we know we’re flipping a fair coin!
Now you probably know this is normal - The probability of getting 9 heads out of 20 flips is &lt;span class=&#34;math inline&#34;&gt;\(P_{9/20}=C_{20}^9(\frac{1}{2})^9(\frac{1}{2})^{11}=16%\)&lt;/span&gt;, not a very low chance at all! This is called sampling variablity.&lt;/p&gt;
&lt;p&gt;Therefore, just because observed data isn’t identical to our expected data, doesn’t mean we should reject our null hypothesis. Now how can we make this decision then?&lt;/p&gt;
&lt;p&gt;Let’s see if we do the same simulation over and over, what the mean looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;means=c()
for (i in c(1:1000))
{
  means = c(means, mean(sample(c(-1,1), 20, replace = TRUE, prob = c(0.5, 0.5))))
}
ggplot(data.frame(means)) + geom_histogram(aes(x=means), binwidth = 0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-11-fdr-correction_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It looks like a normal distribution (sort of)! This tells us that if we do the same experiment over and over again, the mean should be follow a normal distribution and the majority of results should be near where the mean of this normal distribution (&lt;span class=&#34;math inline&#34;&gt;\(\mu=0\)&lt;/span&gt;) is. Is it possible that we get a mean of 0.6 from a fair coin? &lt;strong&gt;Yes, possible but not likely!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Of course, in reality we normally only run an experiment once and therefore, won’t get a distribution of means. But intuitively, we know if our mean is too far away from the center of this normal distribution, our true mean is probably not 0!&lt;/p&gt;
&lt;p&gt;In practice, we compare our sample mean to a &lt;em&gt;t&lt;/em&gt;-distribution. This is because our sample size is relatively small (20 flips) and there is some deviation from normal distribution when we calculate mean based on a small sample size. The shape of a &lt;em&gt;t&lt;/em&gt;-distribution depends on sample size, or degree of freedom (df):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(-4, 4, length=100)
hx &amp;lt;- dnorm(x)

degf &amp;lt;- c(1, 3, 8, 30)
colors &amp;lt;- c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;darkgreen&amp;quot;, &amp;quot;gold&amp;quot;, &amp;quot;black&amp;quot;)
labels &amp;lt;- c(&amp;quot;df=1&amp;quot;, &amp;quot;df=3&amp;quot;, &amp;quot;df=8&amp;quot;, &amp;quot;df=30&amp;quot;, &amp;quot;normal&amp;quot;)

plot(x, hx, type=&amp;quot;l&amp;quot;, lty=2, xlab=&amp;quot;x value&amp;quot;,
  ylab=&amp;quot;Density&amp;quot;, main=&amp;quot;Comparison of t Distributions&amp;quot;)

for (i in 1:4){
  lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}

legend(&amp;quot;topright&amp;quot;, inset=.05, title=&amp;quot;Distributions&amp;quot;,
  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-11-fdr-correction_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Haplotype, LD, and Association Tests</title>
      <link>/post/haplotype-ld-and-association-tests/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/haplotype-ld-and-association-tests/</guid>
      <description>

&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;

&lt;hr /&gt;

&lt;!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#table-of-content&#34;&gt;Table of content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-are-haplotype-and-linkage-disequilibrium-ld&#34;&gt;What Are Haplotype and Linkage Disequilibrium (LD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#quantify-ld&#34;&gt;Quantify LD&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#linkage-disequilibrium-coefficient-d&#34;&gt;Linkage Disequilibrium Coefficient ($D$):&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standardized-linkage-disequilibrium-coefficient-d&#34;&gt;Standardized Linkage Disequilibrium Coefficient ($D&amp;rsquo;$)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-coefficient-gamma2&#34;&gt;Correlation coefficient ($\gamma^2$)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-why-do-we-care-about-ld-and-haplotype&#34;&gt;Now why do we care about LD and haplotype?&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ld-is-an-indication-of-deviation-from-hardy-weinberg-equilibrium&#34;&gt;LD is an indication of deviation from Hardy-Weinberg equilibrium.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /TOC --&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;This is the first post of my QE prep series. I&amp;rsquo;ll be taking notes on my study for general knowledge section of my QE. I&amp;rsquo;m gonna start this off with my favorite topic in our GGG series classes: population genetics&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&#34;what-are-haplotype-and-linkage-disequilibrium-ld&#34;&gt;What Are Haplotype and Linkage Disequilibrium (LD)&lt;/h1&gt;

&lt;p&gt;To properly understand linkage disequilibrium, I want to go back to the &amp;ldquo;Dark Age&amp;rdquo; of genetics, when Gregor Mendel brilliantly discovered (Mendelian) laws of inheritance without any knowledge of the molecular basis.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The First Mendelian Law (Law of Segregation) states that each organism has two alleles for each trait and one of the two alleles is randomly passed on to an offspring during sexual reproduction.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For example, an individual with an AB genotype is eqaully likely to pass an &lt;code&gt;A&lt;/code&gt; allele or a &lt;code&gt;B&lt;/code&gt; allele to its offspring (there are many assumption being made in this statement but I&amp;rsquo;ll roll with it for now).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Second Mendelian Law (Law of Independent Assortment) states that alleles for different traits are passed on independantly from each other during sexual reproduction.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For example, if allelea &lt;code&gt;A/a&lt;/code&gt; controls for trait 1 and alleles &lt;code&gt;B/b&lt;/code&gt; controls for trait 2 (assuming they are not at the same locus), then whether an individual passes on allele &lt;code&gt;A&lt;/code&gt; or &lt;code&gt;a&lt;/code&gt; is independent of wheter it passes on &lt;code&gt;B&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt;. The Independent Assortment implicts the product rule:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Suppose an individual with &lt;code&gt;AaBb&lt;/code&gt; genotype (&lt;code&gt;Aa&lt;/code&gt; at locus 1 and &lt;code&gt;Bb&lt;/code&gt; at locus 2) mates with another individual with same &lt;code&gt;AaBb&lt;/code&gt; genotype, the probability of their offspring being &lt;code&gt;aabb&lt;/code&gt; is &lt;code&gt;1/16&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In case you&amp;rsquo;re wondering how to get this number, here is my favorite way to calculate:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="442px" height="392px" viewBox="-0.5 -0.5 442 392"><defs/><g><rect x="130" y="0" width="120" height="60" fill="#ffffff" stroke="#000000" pointer-events="none"/><g transform="translate(174.5,23.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 30px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">AaBb</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">AaBb</text></switch></g><rect x="320" y="0" width="120" height="60" fill="#ffffff" stroke="#000000" pointer-events="none"/><g transform="translate(364.5,23.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 30px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">AaBb</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">AaBb</text></switch></g><path d="M 190.14 60.29 L 190.02 103.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 190 108.88 L 186.52 101.87 L 190.02 103.63 L 193.52 101.89 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(133.5,113.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="32" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">A: 1/2</div></div></foreignObject><text x="16" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">A: 1/2</text></switch></g><g transform="translate(134.5,153.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 31px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">a: 1/2</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">a: 1/2</text></switch></g><g transform="translate(209.5,153.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 31px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">b: 1/2</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">b: 1/2</text></switch></g><g transform="translate(208.5,113.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="32" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">B: 1/2</div></div></foreignObject><text x="16" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">B: 1/2</text></switch></g><g transform="translate(326.5,113.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="32" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">A: 1/2</div></div></foreignObject><text x="16" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">A: 1/2</text></switch></g><g transform="translate(327.5,153.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 31px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">a: 1/2</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">a: 1/2</text></switch></g><g transform="translate(402.5,153.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 31px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">b: 1/2</div></div></foreignObject><text x="15" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">b: 1/2</text></switch></g><g transform="translate(401.5,113.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="32" height="12" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">B: 1/2</div></div></foreignObject><text x="16" y="12" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">B: 1/2</text></switch></g><g transform="translate(0.5,120.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="118" height="38" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 17px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 118px; white-space: normal; overflow-wrap: normal; font-weight: bold; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">Law of Segregation</div></div></foreignObject><text x="59" y="28" fill="#000000" text-anchor="middle" font-size="17px" font-family="Helvetica" font-weight="bold">Law of Segregation</text></switch></g><path d="M 380 60 L 380 103.63" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 380 108.88 L 376.5 101.88 L 380 103.63 L 383.5 101.88 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><ellipse cx="150" cy="160" rx="22.5" ry="15.000000000000002" fill="none" stroke="#ff0000" pointer-events="none"/><ellipse cx="225" cy="160" rx="22.5" ry="15.000000000000002" fill="none" stroke="#ff0000" pointer-events="none"/><ellipse cx="345" cy="160" rx="22.5" ry="15.000000000000002" fill="none" stroke="#ff0000" pointer-events="none"/><ellipse cx="415" cy="160" rx="22.5" ry="15.000000000000002" fill="none" stroke="#ff0000" pointer-events="none"/><path d="M 150 175 L 185.77 215.24" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 189.26 219.16 L 181.99 216.26 L 185.77 215.24 L 187.22 211.61 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 224.43 174.57 L 193.85 214.92" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 190.68 219.11 L 192.11 211.42 L 193.85 214.92 L 197.69 215.64 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><ellipse cx="190" cy="240" rx="31.499999999999996" ry="20" fill="none" stroke="#000000" pointer-events="none"/><g transform="translate(165.5,230.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="52" height="18" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 17px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 53px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">ab: 1/4</div></div></foreignObject><text x="26" y="18" fill="#000000" text-anchor="middle" font-size="17px" font-family="Helvetica">ab: 1/4</text></switch></g><g transform="translate(8.5,190.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="118" height="58" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 17px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 118px; white-space: normal; overflow-wrap: normal; font-weight: bold; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">Law of Independent Assortment </div></div></foreignObject><text x="59" y="38" fill="#000000" text-anchor="middle" font-size="17px" font-family="Helvetica" font-weight="bold">[Not supported by viewer]</text></switch></g><path d="M 345 175 L 380.77 215.24" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 384.26 219.16 L 376.99 216.26 L 380.77 215.24 L 382.22 211.61 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 419.76 174.47 L 388.86 214.94" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 385.68 219.11 L 387.14 211.42 L 388.86 214.94 L 392.71 215.67 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><ellipse cx="385" cy="240" rx="31.499999999999996" ry="20" fill="none" stroke="#000000" pointer-events="none"/><g transform="translate(359.5,230.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="52" height="18" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 17px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 53px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">ab: 1/4</div></div></foreignObject><text x="26" y="18" fill="#000000" text-anchor="middle" font-size="17px" font-family="Helvetica">ab: 1/4</text></switch></g><path d="M 191.5 260 L 275.28 335.73" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 279.17 339.25 L 271.63 337.15 L 275.28 335.73 L 276.32 331.96 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 385 260 L 285.07 336.14" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 280.89 339.32 L 284.34 332.3 L 285.07 336.14 L 288.58 337.86 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><ellipse cx="280" cy="365" rx="60.00000000000001" ry="25" fill="none" stroke="#000000" pointer-events="none"/><g transform="translate(239.5,355.5)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="81" height="18" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 17px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 82px; white-space: nowrap; overflow-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">aabb: 1/16</div></div></foreignObject><text x="41" y="18" fill="#000000" text-anchor="middle" font-size="17px" font-family="Helvetica">aabb: 1/16</text></switch></g></g></svg>&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In the above diagram, first step involves the Law of Segregation, by which I calculated the probability of each gamete containing each allele separately. The second step is where the Law of Independent Assortment comes into play: The probability of each combination of two alleles is the product of the probabilities of each allele (in one gamete). And the last step is just random combination of two gametes (for a diploid organism).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;However, just as every law has an exception, it was discovered that many of traits in various species didn&amp;rsquo;t really follow the Law of Independent Assortment. The following example shows a case of &amp;ldquo;dependent assortment&amp;rdquo;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Sweet peas have purple (&lt;code&gt;P&lt;/code&gt;) or red (&lt;code&gt;p&lt;/code&gt;) flowers and long (&lt;code&gt;L&lt;/code&gt;) or short (&lt;code&gt;l&lt;/code&gt;) pollen grains. Peas from two pure lines (&lt;code&gt;PPLL&lt;/code&gt; and &lt;code&gt;ppll&lt;/code&gt;) were crossed. The offspring (F1) are all purple flower and long grain (PpLl). They are then self crossed (&lt;code&gt;PpLl&lt;/code&gt; X &lt;code&gt;PpLl&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Assuming indenpendent assortment, we expect to observe all 4 phenotypes in F2 with the following frequencies:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Phenotype&lt;/th&gt;
&lt;th&gt;Frequency&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Purple (P&lt;em&gt;), Long (L&lt;/em&gt;)&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;9&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Purple (P_), Short (ll)&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Red (pp), Long (L_)&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Red (pp), Short (ll)&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;However, large deviations from expected phenotype frequency were observed:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Phenotype&lt;/th&gt;
&lt;th&gt;Exp. Count&lt;/th&gt;
&lt;th&gt;Obs. Count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Purple, Long (P_L_)&lt;/td&gt;
&lt;td&gt;216&lt;/td&gt;
&lt;td&gt;284&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Purple, Short (P_ll)&lt;/td&gt;
&lt;td&gt;72&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Red, Long (ppL_)&lt;/td&gt;
&lt;td&gt;72&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Red, Short (ppll)&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;55&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Data from Bateson et al.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We know that in the parent line (&lt;code&gt;PPLL x ppll&lt;/code&gt;) &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;L&lt;/code&gt; as well as &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;l&lt;/code&gt; are always together because they are both homozygotes. But as the Mendel&amp;rsquo;s second law predicts, they should&amp;rsquo;ve independently assorted from F1 to F2. We, however, see that instead of random combination, &lt;code&gt;P&lt;/code&gt; still appear more often together with &lt;code&gt;L&lt;/code&gt; and so does &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;l&lt;/code&gt;. It&amp;rsquo;s as if &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;L&lt;/code&gt; were somehow linked. This phenomenon is termed &lt;a href=&#34;https://en.wikipedia.org/wiki/Genetic_linkage&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;Linkage&lt;/code&gt;&lt;/a&gt;. We now know that this is because the two loci are closeby on the same chromsome and that during &lt;a href=&#34;https://en.wikipedia.org/wiki/Meiosis&#34; target=&#34;_blank&#34;&gt;meiosis&lt;/a&gt;, DNA on one chromsome are largely segregated together (except some &lt;a href=&#34;https://en.wikipedia.org/wiki/Genetic_recombination&#34; target=&#34;_blank&#34;&gt;recombination&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;When two loci are linked, product rule no longer applies. This causes a non-random association of alleles at different loci in a &lt;strong&gt;given population&lt;/strong&gt;. This is termed &lt;code&gt;Linkage Disequilibrium&lt;/code&gt; or &lt;code&gt;LD&lt;/code&gt;. (Technically LD does not always mean physical linkage. More on this later.)&lt;/p&gt;

&lt;p&gt;When we talk about linkage, knowing genotype of an individual alone is no longer enough: we wish to know which alleles are &amp;ldquo;linked&amp;rdquo; or belong to the same chromsome. In genetics, we call alleles that are on the same chromsome and likely to be inherited together a haplotype. For example, an individual with a &lt;code&gt;PpLl&lt;/code&gt; genotype may have these different haplotypes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PL&lt;/code&gt; and &lt;code&gt;pl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Pl&lt;/code&gt; and &lt;code&gt;pL&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;quantify-ld&#34;&gt;Quantify LD&lt;/h1&gt;

&lt;p&gt;There are several different ways to quntify the extent of linkage between any &lt;strong&gt;two&lt;/strong&gt; loci:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Coefficient of Linkage Disequilibrium (D)&lt;/li&gt;
&lt;li&gt;Normalized coefficient of Linkage Disequilibrium (D&amp;rsquo;)&lt;/li&gt;
&lt;li&gt;Correlation coefficient ($r^2$) and $\chi^2$ test&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;ll briefly go over them below.&lt;/p&gt;

&lt;h2 id=&#34;linkage-disequilibrium-coefficient-d&#34;&gt;Linkage Disequilibrium Coefficient ($D$):&lt;/h2&gt;

&lt;p&gt;As mentioned before, if two loci are independent, their frequencies follow product rule:&lt;/p&gt;

&lt;p&gt;For two independent loci A and B, each with two alleles ($A_1$, $A_2$ and $B_1$, $B_2$, respectively), we have:
    $$f_{A_1B_1} = f_{A_1}f_{B_1}$$
   Now if A and B are not independent, this equation no longer stands true. In that case we have:
    $$f_{A_1B_1} = f_{A_1}f_{B_1} + D$$
  Here we have D as a &lt;em&gt;measurement&lt;/em&gt; of the extent of linkage disequilibrium between $A_1$ and $B_1$. We can calculate the same for all 4 haplotypes:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;$A_1$&lt;/th&gt;
&lt;th&gt;$A_2$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;frequency&lt;/td&gt;
&lt;td&gt;$f_{A_1}$&lt;/td&gt;
&lt;td&gt;$f_{A_2}$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$B_1$&lt;/td&gt;
&lt;td&gt;$f_{B_1}$&lt;/td&gt;
&lt;td&gt;$f_{A_1}f_{B_1} + D_{A_1B_1}$&lt;/td&gt;
&lt;td&gt;$f_{A_2}f_{B_1} + D_{A_2B_1}$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$B_2$&lt;/td&gt;
&lt;td&gt;$f_{B_2}$&lt;/td&gt;
&lt;td&gt;$f_{A_1}f_{B_2} + D_{A_1B_2}$&lt;/td&gt;
&lt;td&gt;$f_{A_2}f_{B_2} + D_{A_2B_2}$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Solve above equations and we get:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$D_{A_1B_1} = f_{A_1B_1} - f_{A_1}f_{B_1}$&lt;/p&gt;

&lt;p&gt;$D_{A_1B_2} = f_{A_1B_2} - f_{A_1}f_{B_2}$&lt;/p&gt;

&lt;p&gt;$D_{A_2B_1} = f_{A_2B_1} - f_{A_2}f_{B_1}$&lt;/p&gt;

&lt;p&gt;$D_{A_2B_2} = f_{A_2B_2} - f_{A_2}f_{B_2}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For a given population, we have&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$f_{A_1} + f_{A_2} = 1$&lt;/p&gt;

&lt;p&gt;$f_{B_1} + f_{B_2} = 1$&lt;/p&gt;

&lt;p&gt;$f_{A_1B_1} + f_{A_1B_2} = f_{A_1}$&lt;/p&gt;

&lt;p&gt;$f_{A_1B_1} + f_{A_2B_1} = f_{B_1}$&lt;/p&gt;

&lt;p&gt;$f_{A_2B_1} + f_{A_2B_2} = f_{A_2} = 1 - f_{A_1}$&lt;/p&gt;

&lt;p&gt;$f_{A_1B_2} + f_{A_2B_2} = f_{B_2} = 1 - f_{B_1}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can then further derive above equations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$D_{A_2B_2} \\\ = f_{A_2B_2} - (1 - f_{A_1})(1 - f_{B_1})
 \\\\ = 1 - f_{B_1} - f_{A_1B_2} - (1 - f_{A_1})(1 - f_{B_1}) \\\ = 1 - f_{B_1} - f_{A_1} - f_{A_1B_1} - (1 - f_{A_1})(1 - f_{B_1}) \\\ = 1 - f_{B_1} - f_{A_1} + f_{A_1B_1} - 1 + f_{B_1} + f_{A_1} - f_{A_1}f_{B_1} \\\ = f_{A_1B_1} - f_{A_1}f_{B_1} = D_{A_1B_1}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Similarly we can prove that $D_{A_1B_1} = - D_{A_1B_2} = - D_{A_2B_1} = D_{A_2B_2} = D$ (note that this is only true for diallelic loci. For loci with more than two alleles, we need to calculate D for each allele pair separately.)&lt;/p&gt;

&lt;p&gt;This makes sense because linkage disequilibrium should be a measurement of two loci not any two specific alleles in those loci. Therefore the D for any haplotype between the two given loci should be the same (or at least the absolute value of it).
We then have:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$D = D_{A_1B_1} = f_{A_1B_1} - f_{A_1}f_{B_1}$&lt;/p&gt;

&lt;p&gt;$D = -D_{A_1B_2} = -f_{A_1B_2} + f_{A_1}f_{B_2}$&lt;/p&gt;

&lt;p&gt;$D = -D_{A_2B_1} = -f_{A_2B_1} + f_{A_2}f_{B_1}$&lt;/p&gt;

&lt;p&gt;$D = D_{A_2B_2} = f_{A_2B_2} - f_{A_2}f_{B_2}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next we can prove that $D = f_{A_1B_1}f_{A_2B_2} - f_{A_1B_2}f_{A_2B_1}$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$f_{A_1B_1}f_{A_2B_2} \\\ = (f_{A_1}f_{B_1} + D)(f_{A_2}f_{B_2} + D) \\\ = f_{A_1}f_{A_2}f_{B_1}f_{B_2} + D(f_{A_1}f_{B_1} + f_{A_2}f_{B_2}) + D^2$&lt;/p&gt;

&lt;p&gt;$f_{A_1B_2}f_{A_2B_1} \\\ = (f_{A_1}f_{B_2} - D)(f_{A_2}f_{B_1} - D) \\\ = f_{A_1}f_{A_2}f_{B_1}f_{B_2} - D(f_{A_1}f_{B_2} + f_{A_2}f_{B_1}) + D^2$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Taske substraction:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$f_{A_1B_1}f_{A_2B_2} - f_{A_1B_2}f_{A_2B_1} \\\ = f_{A_1}f_{A_2}f_{B_1}f_{B_2} + D(f_{A_1}f_{B_1} + f_{A_2}f_{B_2}) + D^2 - (f_{A_1}f_{A_2}f_{B_1}f_{B_2} - D(f_{A_1}f_{B_2} + f_{A_2}f_{B_1}) + D^2) \\\ = D(f_{A_1}f_{B_1} + f_{A_2}f_{B_2} + f_{A_1}f_{B_2} + f_{A_2}f_{B_1}) = D * 1 = D$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we have a measure of linkage disequilibrium. By definition, we know that $D=0$ indicates independent loci (no linkage). What should the maxium value of D be?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Say we have a population with following genotype frequency:
  $f_{A_1} = f_{A_2} = 0.5 \\\ f_{B_1} = f_{B_2} = 0.5$&lt;/p&gt;

&lt;p&gt;Suppose there is complete linkage between $A_1$ and $B_1$, meaning we have following haplotype frequencies:
  $f_{A_1B_1} = f_{A_2B_2} = 0.5 \\\ f_{A_1B_2} = f_{A_2B_1} = 0$&lt;/p&gt;

&lt;p&gt;We can then calculate $D = f_{A_1B_1}f_{A_2B_2} - f_{A_1B_2}f_{A_2B_1} = 0.5 * 0.5 - 0 = 0.25$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When two loci are in complete linkage, we have $D=0.25$.
For any two loci, we always have $D \in [-0.25,0.25]$.&lt;/p&gt;

&lt;p&gt;This scale is not very intuitive but we can work with it. Now next question is, does equal $D$ mean equal linkage disequilibrium?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Consider the following two populations:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pop 1 has haplotype frequencies as follow: $$f_{A_1B_1} = f_{A_2B_2} = 0.34 \\\ f_{A_1B_2} = f_{A_2B_1} = 0.16$$
We can calculate $D = 0.34^2 - 0.16^2 = 0.09$&lt;/li&gt;
&lt;li&gt;Pop 2 has haplotype frequencies as follow: $$f_{A_1B_1} = 0.9 \\\ f_{A_2B_2} = 0.1 \\\ f_{A_1B_2} = f_{A_2B_1} = 0$$
We can calculate $D = 0.9 * 0.1 - 0 = 0.09$&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Even though $D$ at these loci for both populations is exactly the same, we can clearly see that pop 2 has comlete linkage between these two loci while pop 1 does not.&lt;/p&gt;

&lt;p&gt;This example shows a major problem of $D$ for measuring linkage disequilibrium: It&amp;rsquo;s ignorant of allele frequencies in a given population.&lt;/p&gt;

&lt;h2 id=&#34;standardized-linkage-disequilibrium-coefficient-d&#34;&gt;Standardized Linkage Disequilibrium Coefficient ($D&amp;rsquo;$)&lt;/h2&gt;

&lt;p&gt;To address this problem, we can standardize $D$ against allele frequency:
  $$D&amp;rsquo; = \frac{D}{D_{max}}$$&lt;/p&gt;

&lt;p&gt;$D_{max}$ is the maxium possible $D$ in a population with same allele frequencies (but different haplotype frequencies). We have $$D_{max} = f_{maxA_1B_1} - f_{A_1}f_{B_1} \\\ = min(f_{A_1},f_{B_1}) - f_{A_1}f_{B_1}$$
&lt;em&gt;We can also prove that for every haplotype between two given loci, we can get the same $D&amp;rsquo;$.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For example, in the above two populations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Pop 1: $$f_{A_1} = f_{A_2} = f_{B_1} = f_{B_2} = 0.5 \\\ D_{max} = 0.5 - 0.5 * 0.5 = 0.25 \\\ D&amp;rsquo; = \frac{D}{D_{max}} = \frac{0.09}{0.25} = \frac{9}{25} $$&lt;/li&gt;
&lt;li&gt;Pop 2: $$f_{A_1} = f_{B_1} = 0.9 \\\ f_{A_2} = f_{B_2} = 0.1 \\\ D_{max} = 0.9 - 0.9 * 0.9 = 0.09 \\\ D&amp;rsquo; = \frac{D}{D_{max}} = \frac{0.09}{0.09} = 1$$&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we can see that $D&amp;rsquo;$ for population 2 is much higher than that of population 1, indicating a much higher linkage disequilibrium between these loci in pop 2. By definition, we know $D&amp;rsquo; \in [0,1]$&lt;/p&gt;

&lt;p&gt;However, $D&amp;rsquo;$ also has its own problem. Consider the following scenario:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Suppose we genotyped 100 individuals in a population, and count occurrance of each haplotype between loci A and B as follow:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Count&lt;/th&gt;
&lt;th&gt;Total&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$A_1B_1$&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_1B_2$&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_2B_1$&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_2B_2$&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;We can get haplotype and allele frequencies:
  $$f_{A_1B_1} = 0.5, f_{A_1B_2} = 0.49 \\\ f_{A_2B_1} = 0, f_{A_2B_2} = 0.01 \\\ f_{A_1} = 0.99, f_{A_2} = 0.01 \\\ f_{B_1} = 0.5, f_{B_2} = 0.5$$
And calculate $D&amp;rsquo;$:
  $$D&amp;rsquo; = \frac{f_{A_1B_1} * f_{A_2B_2} - f_{A_1B_2} * f_{A_2B_1}}{min(f_{A_1}, f_{B_1}) - f_{A_1}f_{B_1}} = \frac{0.5 * 0.01 - 0.49 * 0}{0.5 - 0.5 * 0.99} = 1$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this case, $D&amp;rsquo;$ indicates strong linkage between the two loci. However, looking at data, we can&amp;rsquo;t confidently make any conclusions regarding the linkage between the two loci. The reason is that in all samples but one, they have either $A_1B_1$ or $A_1B_2$ haplotype. The only one that has an $A_2$ allele can simply be a result of a spontaneous mutaion rather than inheriting from a parent &lt;strong&gt;We do not have enough information to say whether or not A locus is linked with B locus because $A_2$ is mostly missing from data.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In other words, $D&amp;rsquo;$ does not tell us how significant a linkage is or how confident we are in decalring a linkage disequilibrium. For this purpose, we turn to Pearson&amp;rsquo;s correlation coefficient.&lt;/p&gt;

&lt;h2 id=&#34;correlation-coefficient-gamma-2&#34;&gt;Correlation coefficient ($\gamma^2$)&lt;/h2&gt;

&lt;p&gt;Consider the population above:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Count&lt;/th&gt;
&lt;th&gt;Total&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$A_1B_1$&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_1B_2$&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_2B_1$&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$A_2B_2$&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We calculated that $D=0.005$, now instead of  standardizing it like what we did with $D&amp;rsquo;$, we try a different approach:
  $$\gamma^2 = \frac{D^2}{f_{A_1}f_{A_2}f_{B_1}f_{B_2}}$$&lt;/p&gt;

&lt;p&gt;We have $\gamma^2 = \frac{0.005^2}{0.99 * 0.01 * 0.5 * 0.5} = 0.01$&lt;/p&gt;

&lt;p&gt;Now this seems to align well with our assessment of the data! As a matter of fact, this is actually the correlation coefficient of the two variables in this population!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s arbitratrily assign 1 to an $A_1$ allele and -1 to an $A_2$ allele. And 1 to $B_1$, -1 to $B_2$. Now we can plot the data and calculate $\gamma$:&lt;/p&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/QE1_corrPlot.jpeg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Correlation plot&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In the above plot we have $R=0.1$ this is exactly what we calculated above ($\gamma^2 = 0.01$)! Now that we have a correlation coefficient, we can use a $\chi^2$ test on our dataset:&lt;/p&gt;

&lt;p&gt;$$\chi_S^2=\gamma^2*N=0.01*100=1\\\ P(\chi^2&amp;gt;\chi_S^2, df=1) = 0.317 $$&lt;/p&gt;

&lt;p&gt;The p-value is also shown in the above plot. Clearly, we don&amp;rsquo;t see a significant correlation (i.e linkage) between the two loci.&lt;/p&gt;

&lt;p&gt;This is the beauty of $\gamma^2$: it not only tells us the strength of a linkage ($\gamma^2$) but only indicates confidence in such linkage given data ($\chi^2$)!&lt;/p&gt;

&lt;p&gt;Now remember, &lt;strong&gt;the absence of significance is NOT evidence of insignificance!&lt;/strong&gt; Look at the above figure and we notice that the confidence interval of the plot is very large towards $x=-1$. This is because we have only a single data point at $x=-1$. This could easily be a sampling error or like mentioned above, a spontaneous mutation. It is possible, that there are more individuals with $A_2$ allele but we just didn&amp;rsquo;t include them in our samples for unknown reasons. In this case, since we can&amp;rsquo;t estimate frequencies of $A_2$ in haplotype $A_2B_1$ or $A_2B_2$, we can&amp;rsquo;t conclude with any confidence whether or not there is linkage between the two loci.&lt;/p&gt;

&lt;h1 id=&#34;now-why-do-we-care-about-ld-and-haplotype&#34;&gt;Now why do we care about LD and haplotype?&lt;/h1&gt;

&lt;h2 id=&#34;ld-is-an-indication-of-deviation-from-hardy-weinberg-equilibrium&#34;&gt;LD is an indication of deviation from Hardy-Weinberg equilibrium.&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Split a FASTA record by Ns</title>
      <link>/post/split-a-fasta-record-by-ns/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/split-a-fasta-record-by-ns/</guid>
      <description>&lt;p&gt;I want to split sequences in a fasta file at Ns.&lt;/p&gt;

&lt;p&gt;Here is what an example file looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;1_name
ACGTTGCGGCATTCGATCGACGATCGATGCAAACGGTCACGGACTGACTGT
ACACACGTAGCAGCATCAGCATNNNNNNNNNNNNNNNNNNNNGTTGGACGG
NNNNNNNNNNNNGGTGACACACGAGATATATFAGATCAACGTAAGGGATGA
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
AGTCGCTAGCATGCATGGCATATACGCGATCGATTCGATAGCTAGCGNNNN
&amp;gt;2_name
ACGTTGCGGCATTCGATCGACGATCGATGCAAACGGTCACGGACTGACTGT
ACACACGTAGCAGCATCAGCATATTCGATGGCATCGATACCGGTTGGACGG
NNNNNNNNNNNNGGTGACACACGAGATATATFAGATCAACGTAAGGGATGA
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
AGTCGCTAGCATGCATGGCATATACGCGATCGATTCGATAGCTAGCGNNNN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two common formats for FASTA files:&lt;br /&gt;
- Single line FASTA&lt;br /&gt;
    Each record consists of two line: a name line (starts with &amp;ldquo;&amp;gt;&amp;rdquo;) and a sequence line.
- Multiline FASTA&lt;br /&gt;
    Each records consists of multiple lines, First line is a name line (starts with &amp;ldquo;&amp;gt;&amp;rdquo;), followed by multiple lines of sequences.&lt;/p&gt;

&lt;p&gt;Here I assume I&amp;rsquo;m dealing with multiline FASTA because if a script can work with multiline fasta, it&amp;rsquo;s generally easy to make it work with single line files.&lt;/p&gt;

&lt;p&gt;Here is how I approach it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sys

with open(&#39;test&#39;,&#39;r&#39;) as f:
    seq = []
    for line in f:
        if line.startswith(&amp;quot;&amp;gt;&amp;quot;):
            if seq: #seq not empty, process it
                trim = &#39;\n&#39;.join(&#39;&#39;.join(seq).replace(&amp;quot;N&amp;quot;,&amp;quot; &amp;quot;).split())
                print(trim)
                seq = []
            print(line.strip())
        else:
            #Read lines into a single seq
            seq.append(line.strip())
    if seq: #seq not empty, process it
                trim = &#39;\n&#39;.join(&#39;&#39;.join(seq).replace(&amp;quot;N&amp;quot;,&amp;quot; &amp;quot;).split())
                print(trim)
                seq = []
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;1_name
ACGTTGCGGCATTCGATCGACGATCGATGCAAACGGTCACGGACTGACTGTACACACGTAGCAGCATCAGCAT
GTTGGACGG
GGTGACACACGAGATATATFAGATCAACGTAAGGGATGA
AGTCGCTAGCATGCATGGCATATACGCGATCGATTCGATAGCTAGCG
&amp;gt;2_name
ACGTTGCGGCATTCGATCGACGATCGATGCAAACGGTCACGGACTGACTGTACACACGTAGCAGCATCAGCATATTCGATGGCATCGATACCGGTTGGACGG
GGTGACACACGAGATATATFAGATCAACGTAAGGGATGA
AGTCGCTAGCATGCATGGCATATACGCGATCGATTCGATAGCTAGCG
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Calculate row sums and col means with tidyR</title>
      <link>/post/calculate-row-sums-and-col-means-with-tidyr/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/calculate-row-sums-and-col-means-with-tidyr/</guid>
      <description>


&lt;p&gt;Recently Someone asked a question on reddit:
&lt;a href=&#34;https://www.reddit.com/r/Rlanguage/comments/azwcs5/adding_a_row_and_a_column_that_are_means_for_a/&#34;&gt;Adding a row and a column that are means for a set matrix&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a very simple problem that many of us learned how to do only a few hours in to basic R. But since I’ve been learning tidyverse package, I figured why not do it tidy-fashion?&lt;/p&gt;
&lt;p&gt;Let’s give it a try.&lt;/p&gt;
&lt;p&gt;Here is the question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have the following sequence:&lt;br /&gt;
&lt;code&gt;S&amp;lt;-seq(1,90, by=3)&lt;/code&gt;&lt;br /&gt;
I make a matrix that is the following:&lt;br /&gt;
&lt;code&gt;matrix(S, nrow = 6, ncol = 5)&lt;/code&gt;&lt;br /&gt;
Now I am trying to do the following:&lt;br /&gt;
I want to calculate the means of the columns of the matrix and add them as a new row under the columns.&lt;br /&gt;
Next I want to calculate the sum of the rows of the matrix and add them as a new column on the right of the matrix.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here is what their data looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_matrix = matrix(seq(1, 90, by = 3), nrow = 6, ncol = 5)
data_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1   19   37   55   73
## [2,]    4   22   40   58   76
## [3,]    7   25   43   61   79
## [4,]   10   28   46   64   82
## [5,]   13   31   49   67   85
## [6,]   16   34   52   70   88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They want to calculate the mean of each column and sum of each row.&lt;br /&gt;
Now if you know some basic R this can very easily be achieved:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_df = data.frame(data_matrix)
data_df[,ncol(data_df)+1] = rowSums(data_df)
data_df[nrow(data_df)+1,] = colMeans(data_df)
head(data_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X1 X2 X3 X4 X5  V6
## 1  1 19 37 55 73 185
## 2  4 22 40 58 76 200
## 3  7 25 43 61 79 215
## 4 10 28 46 64 82 230
## 5 13 31 49 67 85 245
## 6 16 34 52 70 88 260&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But how can we do this “tidy” way? Turns out this is more complicated than I originally thought.&lt;/p&gt;
&lt;p&gt;First let’s breath some context into our data so we don’t get too bored:&lt;br /&gt;
Let’s say we had an exam in a class of 50 students. The exam consists of 5 questions. TAs recorded the score of each question for each student on an excel sheet. The spreadsheet data has 5 columns, each for a question and 50 rows, each for a student. Now we want to calculate:&lt;br /&gt;
1. Total score for each student (row sums)&lt;br /&gt;
2. Class average for each question (col means)&lt;/p&gt;
&lt;p&gt;Let’s first creat this “spreadsheet”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scores_df = data.frame(matrix(sample(1:20,250, replace = TRUE), nrow = 50, ncol = 5))
head(scores_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X1 X2 X3 X4 X5
## 1 19 13  7  9 16
## 2  5 11 12 14 19
## 3  5 11  6  8 20
## 4  8  9  8  9  6
## 5  3 14  4  7  6
## 6  8 12  6 15 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we have a data frame with 5 colmuns (5 questions) and 50 rows (50 students).&lt;br /&gt;
Now the next step is to for tidy data: key-value pairs.&lt;br /&gt;
First we need to identify the keys: in our dataset, each student-question pair uniquely identifies a value (score). So we can gather our date like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
scores_tibble = gather(rownames_to_column(scores_df, var = &amp;quot;student&amp;quot;), question, score, -student)
head(scores_tibble)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   student question score
## 1       1       X1    19
## 2       2       X1     5
## 3       3       X1     5
## 4       4       X1     8
## 5       5       X1     3
## 6       6       X1     8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here I did not &lt;code&gt;unite()&lt;/code&gt; &lt;code&gt;student&lt;/code&gt; and &lt;code&gt;question&lt;/code&gt; into a single column so that later I can group by either student or question to calculate mean and sum.&lt;br /&gt;
Now to calculate question means:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(group_by(scores_tibble, question), mean = mean(score))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   question  mean
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 X1       11   
## 2 X2       11.1 
## 3 X3        9.7 
## 4 X4        9.78
## 5 X5       10.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Student sum scores:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(group_by(scores_tibble, student), total = sum(score))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 50 x 2
##    student total
##    &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt;
##  1 1          64
##  2 10         46
##  3 11         78
##  4 12         63
##  5 13         50
##  6 14         56
##  7 15         44
##  8 16         40
##  9 17         64
## 10 18         43
## # … with 40 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get a single table with all information&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scores_complete = group_by(scores_tibble, question) %&amp;gt;%
  mutate(question_average = mean(score)) %&amp;gt;%
    group_by(student) %&amp;gt;%
      mutate(student_total = sum(score))
scores_complete&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 250 x 5
## # Groups:   student [50]
##    student question score question_average student_total
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;            &amp;lt;dbl&amp;gt;         &amp;lt;int&amp;gt;
##  1 1       X1          19               11            64
##  2 2       X1           5               11            61
##  3 3       X1           5               11            50
##  4 4       X1           8               11            40
##  5 5       X1           3               11            34
##  6 6       X1           8               11            56
##  7 7       X1           2               11            53
##  8 8       X1           1               11            42
##  9 9       X1          17               11            63
## 10 10      X1           8               11            46
## # … with 240 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a tidy table we can easily calculate stats we want and add them to the original data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scores_df_complete = spread(scores_tibble, question, score) %&amp;gt;%
  left_join(summarise(group_by(scores_tibble, student), student_total = sum(score)), by = &amp;quot;student&amp;quot;) %&amp;gt;%
    bind_rows(spread(summarise(group_by(scores_tibble, question), question_mean = mean(score)), question, question_mean))
head(scores_df_complete)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   student X1 X2 X3 X4 X5 student_total
## 1       1 19 13  7  9 16            64
## 2      10  8 20  4  1 13            46
## 3      11 15 19 10 18 16            78
## 4      12  6 14 13 20 10            63
## 5      13  3  6 13 19  9            50
## 6      14 10 19 10 15  2            56&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tail(scores_df_complete)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    student X1    X2   X3    X4    X5 student_total
## 46      50 12 20.00 17.0 19.00  1.00            69
## 47       6  8 12.00  6.0 15.00 15.00            56
## 48       7  2  9.00 18.0 15.00  9.00            53
## 49       8  1 16.00 11.0  3.00 11.00            42
## 50       9 17  8.00  9.0 11.00 18.00            63
## 51    &amp;lt;NA&amp;gt; 11 11.08  9.7  9.78 10.84            NA&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0700</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0800</pubDate>
      
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    
Click on the **Slides** button above to view the built-in slides feature.

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;em&gt;Slides&lt;/em&gt; feature and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example-slides/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/slides/example-slides/</guid>
      <description>

&lt;h1 id=&#34;welcome-to-slides&#34;&gt;Welcome to Slides&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34;&gt;Academic&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;

&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code block:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;

&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;

&lt;p&gt;Block math:&lt;/p&gt;

&lt;p&gt;$$
f\left( x \right) = \;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;

&lt;p&gt;Make content appear incrementally&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
   One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three
&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;

&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;
&lt;/aside&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;


&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;


&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;

&lt;p&gt;Customize the slide style and background&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;

&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
